{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spark-nlp-spam-analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOSV+C9MpU5EkHYUY3RpcqN"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YF-7h7CJwdwk"
      },
      "source": [
        "**Remarks**\n",
        "\n",
        "In this notebook, we will learn about spam-messaging-classification using spark now!. Yeayy! I used this dataset to analyze (check: https://www.kaggle.com/uciml/sms-spam-collection-dataset). Let's started!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SK8ExHCnvv86",
        "outputId": "8278271a-62ed-4e8b-cd87-49739461c0f2"
      },
      "source": [
        "# firstly, install pyspark\n",
        "!pip install pyspark"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4 MB 65 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 65.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=c022d0cb35961307a736b31c5f1c098524e4ca877ff1396020c8ed8eb9ad0abf\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/0a/c1/9561f6fecb759579a7d863dcd846daaa95f598744e71b02c77\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ9tTbUdwlaV"
      },
      "source": [
        "# import library\n",
        "# 1. pyspark environment\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import udf, lit, when, length\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "# 2. NLP tools\n",
        "import re\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from pyspark.ml.feature import HashingTF, Tokenizer, StopWordsRemover, IDF, StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qo8BiTpxT4H"
      },
      "source": [
        "# setting pyspark environment\n",
        "sc = SparkContext.getOrCreate()\n",
        "spark = SparkSession.Builder().appName('NLP-spam').getOrCreate()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6qzJzWJxq8A",
        "outputId": "b172c1fe-402a-41f9-db40-277d441cb4a0"
      },
      "source": [
        "# preparing dataset\n",
        "data = spark.read.csv('../content/spam-kaggle.csv', inferSchema=True, sep=';')\n",
        "data.printSchema()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- _c0: string (nullable = true)\n",
            " |-- _c1: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnd9TxCMyAGr",
        "outputId": "59df67fb-bedc-4056-95cf-c7b1b28d01a1"
      },
      "source": [
        "data = data.withColumnRenamed('_c0', 'target').withColumnRenamed('_c1', 'text')\n",
        "data.limit(5).show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+--------------------+\n",
            "|target|                text|\n",
            "+------+--------------------+\n",
            "|   ham|Go until jurong p...|\n",
            "|   ham|Ok lar... Joking ...|\n",
            "|  spam|Free entry in 2 a...|\n",
            "|   ham|U dun say so earl...|\n",
            "|   ham|Nah I don't think...|\n",
            "+------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEu1nfzbyEto",
        "outputId": "9fe0ec1a-888c-491f-c415-69086447c0dd"
      },
      "source": [
        "# counting length of the text\n",
        "data = data.withColumn('length', length(data['text']))\n",
        "data.limit(5).show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+--------------------+------+\n",
            "|target|                text|length|\n",
            "+------+--------------------+------+\n",
            "|   ham|Go until jurong p...|   111|\n",
            "|   ham|Ok lar... Joking ...|    29|\n",
            "|  spam|Free entry in 2 a...|   155|\n",
            "|   ham|U dun say so earl...|    49|\n",
            "|   ham|Nah I don't think...|    61|\n",
            "+------+--------------------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOPl_KDD3s4Z",
        "outputId": "c80b7751-aa14-4ca2-af8a-bdcc2e0ffcc3"
      },
      "source": [
        "# groupby data\n",
        "data.groupBy('target').mean().show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-----------------+\n",
            "|target|      avg(length)|\n",
            "+------+-----------------+\n",
            "|   ham| 66.9396140278066|\n",
            "|  spam|138.3190348525469|\n",
            "+------+-----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx9XVftP323M"
      },
      "source": [
        "# cleaning data\n",
        "tokenizer = Tokenizer(inputCol='text', outputCol='tokens')\n",
        "stop_remove = StopWordsRemover(inputCol='tokens', outputCol='stop_token')\n",
        "tf_vec = HashingTF(inputCol='stop_token', outputCol='c_vec')\n",
        "idf = IDF(inputCol='c_vec', outputCol='tf_idf')\n",
        "ham_spam_to_numeric = StringIndexer(inputCol='target', outputCol='label')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFnvwSNB4lvH"
      },
      "source": [
        "# vectorization\n",
        "clean_up = VectorAssembler(inputCols=['tf_idf', 'length'], outputCol='features')\n",
        "model = NaiveBayes()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCMslJf-5Etu"
      },
      "source": [
        "# splitting data\n",
        "train, test = data.randomSplit([0.7,0.3])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV9e6Jqn5LYp"
      },
      "source": [
        "# using pipeline\n",
        "pipeline = Pipeline(stages=[ham_spam_to_numeric, \n",
        "                            tokenizer, \n",
        "                            stop_remove,\n",
        "                            tf_vec,\n",
        "                            idf,\n",
        "                            clean_up,\n",
        "                            model\n",
        "                            ])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMA7UiYl5g_b"
      },
      "source": [
        "# training model\n",
        "clf = pipeline.fit(train)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLCZNoN_5kuA"
      },
      "source": [
        "# predicting test\n",
        "predictions = clf.transform(test)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MP9uhNz05_xU",
        "outputId": "1ad14b66-8153-4203-d82e-a5a05303c00e"
      },
      "source": [
        "predictions.limit(5).show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|target|                text|length|label|              tokens|          stop_token|               c_vec|              tf_idf|            features|       rawPrediction|         probability|prediction|\n",
            "+------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|   ham|                 &lt|     4|  0.0|             [, &lt]|             [, &lt]|(262144,[248474,2...|(262144,[248474,2...|(262145,[248474,2...|[-49.182181451882...|[1.0,1.9775394158...|       0.0|\n",
            "|   ham|                 &lt|     4|  0.0|             [, &lt]|             [, &lt]|(262144,[248474,2...|(262144,[248474,2...|(262145,[248474,2...|[-49.182181451882...|[1.0,1.9775394158...|       0.0|\n",
            "|   ham| gonna let me kno...|    95|  0.0|[, gonna, let, me...|[, gonna, let, kn...|(262144,[238,1777...|(262144,[238,1777...|(262145,[238,1777...|[-758.22945683397...|[1.0,8.9420326120...|       0.0|\n",
            "|   ham|\"7 wonders in My ...|   156|  0.0|[\"7, wonders, in,...|[\"7, wonders, wor...|(262144,[21077,59...|(262144,[21077,59...|(262145,[21077,59...|[-1529.4992249882...|[1.0,3.5359049448...|       0.0|\n",
            "|   ham|\"A swt thought: \\...|   161|  0.0|[\"a, swt, thought...|[\"a, swt, thought...|(262144,[8804,380...|(262144,[8804,380...|(262145,[8804,380...|[-1612.7561408674...|[1.0,8.0553300069...|       0.0|\n",
            "+------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SicO1irk6CHr"
      },
      "source": [
        "# evaluating model\n",
        "evaluatorMulti = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction')\n",
        "\n",
        "predictionAndTarget = predictions.select(\"label\", \"prediction\")\n",
        "\n",
        "# showing metrics\n",
        "acc = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName:\"accuracy\"})\n",
        "f1 = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName:\"f1\"})\n",
        "precision = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName:\"weightedPrecision\"})\n",
        "recall = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName:\"weightedRecall\"})"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Se8ENZVb7BxC",
        "outputId": "bc4d43c9-46ef-4363-decd-8eaa5a20e793"
      },
      "source": [
        "print('Accuracy:  {:2.2%} '.format(acc))\n",
        "print('Precision: {:2.2%} '.format(precision))\n",
        "print('Recall:    {:2.2%} '.format(recall))\n",
        "print('F1 Score:  {:2.2%} '.format(f1))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  96.56% \n",
            "Precision: 96.59% \n",
            "Recall:    96.56% \n",
            "F1 Score:  96.37% \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}